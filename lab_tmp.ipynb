{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: modelzoo/timesformer_6x43x1_minik.pth\n"
     ]
    }
   ],
   "source": [
    "#timesformer model\n",
    "\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from mmcv.runner import get_dist_info\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.cnn import fuse_conv_bn\n",
    "from mmcv.fileio.io import file_handlers\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import get_dist_info, init_dist, load_checkpoint\n",
    "from mmcv.runner.fp16_utils import wrap_fp16_model\n",
    "\n",
    "#from mmaction.apis import multi_gpu_test, single_gpu_test\n",
    "from mmaction.apis import multi_gpu_test \n",
    "from mmaction.datasets import build_dataloader, build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.utils import register_module_hooks\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from mmaction.models.recognizers import GumbelSampler2DRecognizer2D, Sampler2DRecognizer2D, Sampler2DRecognizer3D\n",
    "from mmaction.models.backbones import MobileNetV2TSM, ResNet, MobileNetV2\n",
    "from mmaction.models.backbones.mobilenet_v2 import InvertedResidual\n",
    "from mmaction.models.heads import TSMHead\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset, build_dataloader\n",
    "from mmcv.runner import get_dist_info, init_dist, load_checkpoint\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from mmaction.core.evaluation.accuracy import top_k_accuracy, mean_average_precision\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "\n",
    "# config = \"configs/anet_timesformer_uniform10.py\"\n",
    "# checkpoint = \"modelzoo/timesformer_6x100x1_anet.pth\"\n",
    "\n",
    "config = \"configs/minik_timesformer_uniform10.py\"\n",
    "checkpoint = \"modelzoo/timesformer_6x43x1_minik.pth\"\n",
    "\n",
    "# config = \"configs/single_anet_timesformer_6x100x1.py\"\n",
    "# checkpoint = \"modelzoo/timesformer_6x100x1_anet.pth\"\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "# dataset = build_dataset(cfg.data.train, dict(test_mode=True))\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "dataloader_setting = dict(dataloader_setting,\n",
    "                            **cfg.data.get('test_dataloader', {}))\n",
    "data_loader = build_dataloader(dataset, **dataloader_setting)\n",
    "\n",
    "model = build_model(\n",
    "        cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))\n",
    "load_checkpoint(model, checkpoint, map_location='cpu')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_gpu_test(model, data_loader, mode='score1frame'):\n",
    "    \"\"\"Test model with a single gpu.\n",
    "\n",
    "    This method tests model with a single gpu and displays test progress bar.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to be tested.\n",
    "        data_loader (nn.Dataloader): Pytorch data loader.\n",
    "\n",
    "    Returns:\n",
    "        list: The prediction results.\n",
    "    \"\"\"\n",
    "    print(\"############################################################\")\n",
    "    results = []\n",
    "    sampled_indice = []\n",
    "    rconfs = []\n",
    "    wconfs = []\n",
    "    dataset = data_loader.dataset\n",
    "    prog_bar = mmcv.ProgressBar(len(dataset))  \n",
    "    start = time.time()\n",
    "    total_seg = 10\n",
    "    perm_num = 6\n",
    "    perms = torch.tensor(list(combinations([i for i in range(total_seg)],perm_num)))\n",
    "    softmax = True\n",
    "    for data in data_loader:\n",
    "        end = time.time()\n",
    "        # print(f\"Get data {end - start:.5f} sec\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            imgs, labels = data['imgs'], data['label'].squeeze()\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            # print(f\"labels = {labels}\")           \n",
    "\n",
    "            if mode == 'two':\n",
    "                B, T, C, H, W = imgs.shape\n",
    "                imgs = imgs.reshape(B*T, C, H, W)\n",
    "                feats = model.extract_feat(imgs)\n",
    "                logits = model.cls_head(feats, 1)\n",
    "                logits = logits.reshape(B, T, -1)\n",
    "                # print(f\"labels = {labels}\")\n",
    "                label_logits = logits[range(B), :, labels.squeeze()]\n",
    "                max_idx = label_logits.max(-1)[1]\n",
    "                logits = logits[range(B), max_idx]\n",
    "                result = logits.detach().cpu().numpy()\n",
    "\n",
    "                # for i in range(num_segs):\n",
    "                #     logits = model.cls_head(feats[i:i+1], 1)\n",
    "                #     if logits.softmax(-1)[:,labels.bool()] > result:\n",
    "                #         result = logits\n",
    "\n",
    "                    # print(result)\n",
    "            elif mode == 'original':\n",
    "                B, N, C, T, H, W = imgs.shape\n",
    "                imgs = imgs.reshape(B, C, T, H, W)\n",
    "                x = model.extract_feat(imgs)\n",
    "                logits = model.cls_head(x)\n",
    "                result = logits.detach().cpu().numpy()\n",
    "            elif mode == 'bruteforce':\n",
    "                B, N, C, T, H, W = imgs.shape\n",
    "                imgs = rearrange(imgs, 'b n c t h w -> (b n) c t h w')\n",
    "                perm_logits = []\n",
    "                score = torch.zeros([B, total_seg]).cuda()\n",
    "                # best = torch.ones([B]).cuda() * -100\n",
    "                for perm in perms:\n",
    "                    indice = torch.tensor([1 if i in perm else 0 for i in range(total_seg)]).bool()\n",
    "                    x = model.cls_head(model.extract_feat(imgs[:,:,indice]))\n",
    "                    if softmax:\n",
    "                        x = x.softmax(-1)\n",
    "                    perm_logits.append(x) # B num_classes\n",
    "                perm_logits = torch.stack(perm_logits, 1) # B len(perms) C\n",
    "                label_logits = perm_logits[range(B), :, labels.squeeze()]\n",
    "                max_idx = label_logits.max(-1)[1]\n",
    "                sampled_indice.extend(perms[max_idx].detach().cpu().numpy())\n",
    "                result = perm_logits[range(B), max_idx, :]\n",
    "                result = result.detach().cpu().numpy()\n",
    "            elif mode == 'score2frame':\n",
    "                B, N, C, T, H, W = imgs.shape\n",
    "                perm_imgs = []\n",
    "                score = torch.zeros([B, total_seg]).cuda()\n",
    "                for perm in perms:\n",
    "                    indice = torch.tensor([1 if i in perm else 0 for i in range(total_seg)]).bool()\n",
    "                    perm_imgs.append(imgs[:,:,:,indice])\n",
    "                perm_imgs = torch.stack(perm_imgs, 1)\n",
    "                perm_imgs = rearrange(perm_imgs, 'b p n c t h w -> (b p n) c t h w')\n",
    "                x = model.extract_feat(perm_imgs)\n",
    "                logits = model.cls_head(x) # B*len(perms) num_classes\n",
    "                if softmax:\n",
    "                    logits = logits.softmax(-1)\n",
    "                logits = rearrange(logits, '(b p) n -> b p n', b = B, p = len(perms)) # B len(perms) num_classes\n",
    "                label_logits = logits[range(B), :, labels.squeeze()]\n",
    "                # for i in range(len(perms)):\n",
    "                #     for j in range(len(perms[i])):\n",
    "                #         score[:, perms[i][j]] += label_logits[:, i]\n",
    "                total_score = label_logits.sum(-1)\n",
    "                tmp = torch.zeros_like(total_score)\n",
    "                for i in range(total_seg):\n",
    "                    for j in range(len(perms)):\n",
    "                        if i in perms[j]:\n",
    "                            tmp += label_logits[:, j]\n",
    "                    score[:, i] = total_score - tmp\n",
    "                max_idx = score.topk(6, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "                batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "                imgs = rearrange(imgs, 'b n c t h w -> (b n) t c h w')\n",
    "                sampled_imgs = imgs[batch_inds, max_idx]\n",
    "                sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "                fx = model.extract_feat(sampled_imgs)\n",
    "                flogits = model.cls_head(fx)\n",
    "                result = flogits.detach().cpu().numpy()\n",
    "            elif mode == 'score1frame':\n",
    "                B, N, C, T, H, W = imgs.shape\n",
    "                imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "                # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "                x = model.extract_feat(imgs.unsqueeze(2))\n",
    "                logits = model.cls_head(x) # B*T num_classes\n",
    "                if softmax:\n",
    "                    logits = logits.softmax(-1)\n",
    "\n",
    "                dlabels = labels.clone().unsqueeze(1).repeat(1,total_seg).flatten()\n",
    "                y_hat = logits.argmax(-1)\n",
    "                # rconf = logits[y_hat == dlabels]\n",
    "                # wconf = logits[y_hat != dlabels]\n",
    "                # rtmp = dlabels[y_hat == dlabels]\n",
    "                # wtmp = dlabels[y_hat != dlabels]\n",
    "                # rconfs.extend(rconf[range(rtmp.shape[0]),rtmp])\n",
    "                # wconfs.extend(wconf[range(wtmp.shape[0]),wtmp])\n",
    "\n",
    "                logits = logits.reshape(B, T, -1)                    \n",
    "                label_logits = logits[range(B), :, labels.squeeze()]\n",
    "                # rconfs.extend(label_logits)\n",
    "\n",
    "                max_idx = label_logits.topk(6, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "                # rconf, max_idx = label_logits.topk(6, dim=1)\n",
    "                # max_idx = max_idx.sort(dim=1,descending=False)[0]\n",
    "                # rconfs.extend(rconf)\n",
    "\n",
    "                batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "                imgs = rearrange(imgs, '(b t) c h w -> b t c h w', b=B, t=T)\n",
    "                sampled_imgs = imgs[batch_inds, max_idx]\n",
    "                sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "\n",
    "                fx = model.extract_feat(sampled_imgs)\n",
    "                flogits = model.cls_head(fx)\n",
    "                result = flogits.detach().cpu().numpy()\n",
    "                sampled_indice.extend(max_idx.detach().cpu().numpy())\n",
    "                # max_idx = label_logits.max(-1)[1]\n",
    "                # result = logits[range(B), max_idx, :]\n",
    "                # result = result.detach().cpu().numpy()\n",
    "            elif mode == 'entropy':\n",
    "                B, N, C, T, H, W = imgs.shape\n",
    "                imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "                # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "                x = model.extract_feat(imgs.unsqueeze(2))\n",
    "                logits = model.cls_head(x) # B*T num_classes\n",
    "                logits = logits.softmax(-1)\n",
    "                negative_entropy = (logits * torch.log(logits)).sum(-1)\n",
    "                negative_entropy = negative_entropy.reshape(B, T)\n",
    "                max_idx = negative_entropy.topk(5, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "                batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "                imgs = rearrange(imgs, '(b t) c h w -> b t c h w', b=B, t=T)\n",
    "                sampled_imgs = imgs[batch_inds, max_idx]\n",
    "                sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "\n",
    "                fx = model.extract_feat(sampled_imgs)\n",
    "                flogits = model.cls_head(fx)\n",
    "                result = flogits.detach().cpu().numpy()\n",
    "            elif mode == 'max_confidence':\n",
    "                B, N, C, T, H, W = imgs.shape\n",
    "                imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "                # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "                x = model.extract_feat(imgs.unsqueeze(2))\n",
    "                logits = model.cls_head(x) # B*T num_classes\n",
    "                logits = logits.softmax(-1)\n",
    "                argmax_indice = logits.argmax(-1)\n",
    "                # print(\"argmax_indice = \", argmax_indice.shape)\n",
    "                argmax_logits = logits[range(B*T), argmax_indice.squeeze()]\n",
    "                # print(\"argmax_logits = \",argmax_logits.shape)\n",
    "                argmax_logits = argmax_logits.reshape(B, T)\n",
    "                # print(\"argmax_logits reshape = \",argmax_logits.shape)\n",
    "                \n",
    "                max_idx = argmax_logits.topk(6, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "                # print(\"max_idx = \", max_idx)\n",
    "                batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "                imgs = rearrange(imgs, '(b t) c h w -> b t c h w', b=B, t=T)\n",
    "                sampled_imgs = imgs[batch_inds, max_idx]\n",
    "                sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "\n",
    "                fx = model.extract_feat(sampled_imgs)\n",
    "                flogits = model.cls_head(fx)\n",
    "                result = flogits.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        results.extend(result)\n",
    "        # print(np.asarray(results).shape)\n",
    "        # use the first key as main key to calculate the batch size\n",
    "        batch_size = len(next(iter(data.values())))\n",
    "        for _ in range(batch_size):\n",
    "            prog_bar.update()\n",
    "        start = time.time()\n",
    "        # results = collect_results_gpu(results, len(dataset))\n",
    "    return results, sampled_indice, rconfs, wconfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 9858/9858, 12.9 task/s, elapsed: 763s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "results, sampled_indice, rconfs, wconfs = single_gpu_test(model, data_loader, mode='score1frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sampled_indice = np.asarray(sampled_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 7],\n",
       "       [0, 1, 4, 5, 6, 7],\n",
       "       [3, 4, 5, 7, 8, 9],\n",
       "       ...,\n",
       "       [0, 1, 4, 7, 8, 9],\n",
       "       [0, 2, 4, 5, 7, 8],\n",
       "       [0, 1, 2, 4, 5, 7]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(results, './tensors/minik_u10to6_logit_s_result.pt')\n",
    "torch.save(sampled_indice, './tensors/minik_u10to6_logit_s_indice.pt')\n",
    "# torch.save(sampled_indice, './tensors/anet_u10to6_oracle_s_indice.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = 'mean_average_precision'\n",
    "metrics = 'top_k_accuracy'\n",
    "\n",
    "eval_config = cfg.get('eval_config', {})\n",
    "eval_config = Config._merge_a_into_b(dict(metrics=metrics), eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.7943\n",
      "top5_acc\t0.9387\n",
      "top1_acc: 0.7943\n",
      "top5_acc: 0.9387\n"
     ]
    }
   ],
   "source": [
    "eval_res = dataset.evaluate(results, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Cross Entropy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 16:17:11,678 - mmaction - INFO - log from modelzoo/mini_kinetics_mobilenetv2_tsm_sampler_checkpoint.pth\n",
      "2023-01-30 16:17:11,679 - mmaction - INFO - load checkpoint from local path: modelzoo/mini_kinetics_mobilenetv2_tsm_sampler_checkpoint.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: work_dirs/minik_mbnv2/best_mean_average_precision_epoch_16.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile('configs/minik_mbnv2.py')\n",
    "checkpoint = \"work_dirs/minik_mbnv2/best_mean_average_precision_epoch_16.pth\"\n",
    "mbnet = build_model(\n",
    "        cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))\n",
    "load_checkpoint(mbnet, checkpoint, map_location='cpu')\n",
    "mbnet.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 9858/9858, 25.0 task/s, elapsed: 395s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "prog_bar = mmcv.ProgressBar(len(dataset))\n",
    "results = []\n",
    "for data in data_loader:\n",
    "    model.eval()\n",
    "    mbnet.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs, labels = data['imgs'], data['label'].squeeze()\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        B, N, C, T, H, W = imgs.shape\n",
    "        imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "        # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "        probs = mbnet.extract_feat(F.interpolate(imgs, size=128))\n",
    "        probs = mbnet.cls_head(probs)\n",
    "        probs = probs.softmax(-1)\n",
    "        max_score, max_index = torch.max(probs, -1) # [B * T]\n",
    "        max_score = max_score.reshape(B, T) # [B, T]\n",
    "        sample_index = max_score.topk(6, dim=1)[1]\n",
    "        sample_index, _ = sample_index.sort(dim=1, descending=False)\n",
    "        batch_inds = torch.arange(B).unsqueeze(-1).expand_as(sample_index)\n",
    "        imgs = rearrange(imgs, '(b t) c h w -> b t c h w', b = B, t = T)\n",
    "        sampled_imgs = imgs[batch_inds, sample_index] # sampled_imgs [B, t, C, H, W], where t is the number of sampled frames\n",
    "        sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "        x = model.extract_feat(sampled_imgs)\n",
    "        flogits = model.cls_head(x)\n",
    "        result = flogits.detach().cpu().numpy()\n",
    "    results.extend(result)\n",
    "    # print(np.asarray(results).shape)\n",
    "    # use the first key as main key to calculate the batch size\n",
    "    batch_size = len(next(iter(data.values())))\n",
    "    for _ in range(batch_size):\n",
    "        prog_bar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = 'mean_average_precision'\n",
    "metrics = 'top_k_accuracy'\n",
    "\n",
    "eval_config = cfg.get('eval_config', {})\n",
    "eval_config = Config._merge_a_into_b(dict(metrics=metrics), eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.8009\n",
      "top5_acc\t0.9407\n",
      "top1_acc: 0.8009\n",
      "top5_acc: 0.9407\n"
     ]
    }
   ],
   "source": [
    "eval_res = dataset.evaluate(results, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 21:54:00,813 - mmaction - INFO - log from modelzoo/mini_kinetics_mobilenetv2_tsm_sampler_checkpoint.pth\n",
      "2023-01-30 21:54:00,814 - mmaction - INFO - load checkpoint from local path: modelzoo/mini_kinetics_mobilenetv2_tsm_sampler_checkpoint.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: work_dirs/mini_kinetics_kd_bpr_mbnv2_timesformer/epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "config = \"work_dirs/mini_kinetics_kd_bpr_mbnv2_timesformer/minik_kd_bpr_mbnv2_timesformer.py\"\n",
    "checkpoint = \"work_dirs/mini_kinetics_kd_bpr_mbnv2_timesformer/epoch_10.pth\"\n",
    "\n",
    "# config = \"configs/single_anet_timesformer_6x100x1.py\"\n",
    "# checkpoint = \"modelzoo/timesformer_6x100x1_anet.pth\"\n",
    "\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "dataset = build_dataset(cfg.data.train, dict(test_mode=True))\n",
    "# dataset = build_dataset(cfg.data.train, dict(test_mode=True))\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "dataloader_setting = dict(dataloader_setting,\n",
    "                            **cfg.data.get('test_dataloader', {}))\n",
    "data_loader = build_dataloader(dataset, **dataloader_setting)\n",
    "\n",
    "model = build_model(\n",
    "        cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))\n",
    "load_checkpoint(model, checkpoint, map_location='cpu')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>] 113911/113911, 11.9 task/s, elapsed: 9606s, ETA:     0s:"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "prog_bar = mmcv.ProgressBar(len(dataset))\n",
    "loss = torch.nn.MSELoss()\n",
    "mse = 0\n",
    "for data in data_loader:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs, labels = data['imgs'], data['label'].squeeze()\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        B, N, C, T, H, W = imgs.shape\n",
    "        imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "        # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "        x_s = model.sampler(F.interpolate(imgs, size=128)).squeeze()\n",
    "        probs = model.sample_forward(x_s, T)\n",
    "        x = model.extract_feat(imgs.unsqueeze(2))\n",
    "        cls_score = model.cls_head(x)\n",
    "        gt_labels = labels.squeeze()\n",
    "        cls_score = cls_score.reshape(B, T, -1)\n",
    "        gt_logit = cls_score[range(B),:,gt_labels] # [B, T]\n",
    "        gt_logit[gt_logit >= 0.3] = 1.0\n",
    "        gt_logit[gt_logit < 0.3] = 0.0\n",
    "        mse += loss(probs, gt_logit) * B\n",
    "    batch_size = len(next(iter(data.values())))\n",
    "    for _ in range(batch_size):\n",
    "        prog_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2457, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse / 113911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idataloader = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(idataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imgs, labels = data['imgs'], data['label'].squeeze()\n",
    "    imgs, labels = imgs.cuda(), labels.cuda()\n",
    "    B, N, C, T, H, W = imgs.shape\n",
    "    imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "    # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "    x_s = model.sampler(F.interpolate(imgs, size=128)).squeeze()\n",
    "    probs = model.sample_forward(x_s, T)\n",
    "    x = model.extract_feat(imgs.unsqueeze(2))\n",
    "    cls_score = model.cls_head(x)\n",
    "    gt_labels = labels.squeeze()\n",
    "    cls_score = cls_score.softmax(-1)\n",
    "    cls_score = cls_score.reshape(B, T, -1)\n",
    "    gt_logit = cls_score[range(B),:,gt_labels] # [B, T]\n",
    "    gt_logit[gt_logit >= 0.3] = 1.0\n",
    "    gt_logit[gt_logit < 0.3] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "anet_logit_indice = torch.load(\"tensors/anet_u10to6_logit_s_indice.pt\")\n",
    "anet_oracle_indice = torch.load(\"tensors/anet_u10to6_oracle_s_indice.pt\")\n",
    "\n",
    "minik_logit_indice = torch.load(\"tensors/minik_u10to6_logit_s_indice.pt\")\n",
    "minik_oracle_indice = torch.load(\"tensors/minik_u10to6_oracle_s_indice.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9858, 6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minik_logit_indice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9858, 6)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minik_oracle_indice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4926, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minik_logit_indice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in range(len(minik_logit_indice)):\n",
    "    gt = minik_oracle_indice[i]\n",
    "    pred = minik_logit_indice[i]\n",
    "    score = 0\n",
    "    for j in range(6):\n",
    "        if pred[j] in gt:\n",
    "            score += 1\n",
    "    total += (score / 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718976127679722"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/len(minik_logit_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4926, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anet_oracle_indice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in range(len(anet_logit_indice)):\n",
    "    gt = anet_oracle_indice[i]\n",
    "    pred = anet_logit_indice[i]\n",
    "    score = 0\n",
    "    for j in range(6):\n",
    "        if pred[j] in gt:\n",
    "            score += 1\n",
    "    total += (score / 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209703613479477"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/len(anet_logit_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6677660950330118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def ndcg(rel_true, rel_pred, p=None, form=\"linear\"):\n",
    "    \"\"\" Returns normalized Discounted Cumulative Gain\n",
    "    Args:\n",
    "        rel_true (1-D Array): relevance lists for particular user, (n_songs,)\n",
    "        rel_pred (1-D Array): predicted relevance lists, (n_pred,)\n",
    "        p (int): particular rank position\n",
    "        form (string): two types of nDCG formula, 'linear' or 'exponential'\n",
    "    Returns:\n",
    "        ndcg (float): normalized discounted cumulative gain score [0, 1]\n",
    "    \"\"\"\n",
    "    rel_true = np.sort(rel_true)[::-1]\n",
    "    p = min(len(rel_true), min(len(rel_pred), p))\n",
    "    discount = 1 / (np.log2(np.arange(p) + 2))\n",
    "\n",
    "    if form == \"linear\":\n",
    "        idcg = np.sum(rel_true[:p] * discount)\n",
    "        dcg = np.sum(rel_pred[:p] * discount)\n",
    "    elif form == \"exponential\" or form == \"exp\":\n",
    "        idcg = np.sum([2**x - 1 for x in rel_true[:p]] * discount)\n",
    "        dcg = np.sum([2**x - 1 for x in rel_pred[:p]] * discount)\n",
    "    else:\n",
    "        raise ValueError(\"Only supported for two formula, 'linear' or 'exp'\")\n",
    "\n",
    "    return dcg / idcg\n",
    "\n",
    "ndcg_sum = 0\n",
    "for i in range(len(minik_oracle_indice)):\n",
    "    ndcg_sum += ndcg(minik_oracle_indice[i], minik_logit_indice.numpy()[i], 6)\n",
    "ndcg_mean = ndcg_sum / len(minik_oracle_indice)\n",
    "print(ndcg_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_296844/1934892733.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminik_oracle_indice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminik_logit_indice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "p = None\n",
    "p = min(len(minik_oracle_indice[i]), min(len(minik_logit_indice[i]), p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(minik_oracle_indice[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 7])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minik_logit_indice[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_296844/1572006402.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminik_logit_indice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "min(len(minik_logit_indice[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = torch.load(\"modelzoo/mini_kinetics_mobilenetv2_tsm_sampler_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 3, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 4, 6, 7],\n",
       "       [0, 3, 4, 5, 6, 9],\n",
       "       [0, 4, 5, 7, 8, 9],\n",
       "       ...,\n",
       "       [0, 1, 4, 7, 8, 9],\n",
       "       [2, 3, 4, 5, 8, 9],\n",
       "       [0, 1, 2, 4, 5, 6]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minik_oracle_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 7],\n",
       "        [0, 1, 4, 5, 6, 7],\n",
       "        [3, 4, 5, 7, 8, 9],\n",
       "        ...,\n",
       "        [0, 1, 4, 7, 8, 9],\n",
       "        [0, 2, 4, 5, 7, 8],\n",
       "        [0, 1, 2, 4, 5, 7]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minik_logit_indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_179922/912977433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrconfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# y = torch.stack(wconfs, 0).flatten().cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.stack(rconfs, 0).flatten().cpu()\n",
    "# y = torch.stack(wconfs, 0).flatten().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "\n",
    "# Plot Histogram on x\n",
    "plt.hist(x, bins=100, label='correct')\n",
    "plt.hist(y, bins=100, label='wrong', alpha=0.7)\n",
    "plt.legend()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAGlCAYAAABOcQq+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv/ElEQVR4nO3dfXxV5Z3v/c8PMCDGICoSq6iMIKWoqIAtOMNhcFCm2o49HdsqtxXH0YMKVVurw4xVpLbWtlqtcvToYEFv0N5qq/WoTW8sjNaqtVp8qJRpz1C15ak+AAXkQbnOH3vtdBMSSEJ29kryeb9e65Xsa/3WWtfKIjtfrvWwI6WEJEmS8qNbpTsgSZKk7RnQJEmScsaAJkmSlDMGNEmSpJwxoEmSJOWMAU2SJClnDGiSJEk5Y0CTJEnKmR6V7kAlRUQAHwL+XOm+SJKkLmFvYHnaxScFdOmARiGc/aHSnZAkSV3KwcAfd1bQ1QPanwHefPNNampqKt0XSZLUia1bt44BAwZAM87ctTigRcRY4MvACOBA4FMppYeaqL0d+B/ApSmlm0ra9wVuAT4BbAMeBC5OKa0vqTkamAWMAv4E3JJS+maD9Z8OfBU4DPgtcEVK6bGW7lNNTY0BTZIk5UZrbhLYC3gJuGhnRRHxKeBjwPJGZs8DhgETgFOBscAdJcvWAD8BXqcQBL8MzIiI80tqxgD3ArOBY4GHgIci4shW7JMkSVJuxC6uUdv5whGJRkbQIuIg4DngZOBR4KbiCFpEDAVeA0allH6ZtU0EHgMOTiktj4gLgK8BtSmlLVnNN4DTUkofzl5/H9grpXRqyXafBRanlKY0s/81wNq1a9c6giZJkspq3bp19OnTB6BPSmndzmrb/DEbEdENuAf4Vkrp142UjAbWFMNZZgGFU50fLal5shjOMnXAkIjoW1KzoMG667L2pvrWMyJqihOFOykkSZJypRw3CVwBvA98t4n5tcDq0oaU0vsR8U42r1izrMFyq0rmvZt9XdVITS1Nmw5cvbPON7Rt2za2bNmy60J1ClVVVXTr5uMBJUmV1aYBLSJGABcDx+3q+R4Vch1wY8nrvdnJYza2bNnCsmXL2LZtW9k7pnzo1q0bAwcOpKqqqtJdkSR1YW09gvY3wAHAG4VnwALQHbghIi5JKR0GrMxq6kVED2DfbB7Z1/4N1t2/ZN7OalbShJTSZmBzyXab3JGUEitWrKB79+4MGDDAUZUuYNu2bSxfvpwVK1ZwyCGH7PTfhyRJ5dTWAe0eGr8u7B7ge9nrZ4B9ImJESumFrG08hevhniup+VpE7JFS2pq1TQCWppTeLak5EbipZFsTsvbd9v7777Nx40Y+9KEP0bt377ZYpTqAfv36sXz5ct5//3322GOPSndHktRFteY5aNXAoJKmgRFxDPBOSukN4O0G9VuBlSmlpQAppSUR8WPgzoiYAuwB3Arcl1IqPpJjPoVrxWZHxPXAkRROnV5asuqbgf+IiC9RuFP0c8BI4HzawAcffADgqa4upni8P/jgAwOaJKliWnPebiTwq2yCwjVdvwJmtmAdk4DfAE9QeLzGzygJVimltcBJwEDgBeAGYGZK6Y6Smp8DZ2bLvQT8I4XHcLzain1qkqe5uhaPtyQpD1o8gpZSWgQ0+69Ydt1Zw7Z3KISrnS33MoVr2nZWcz9wf3P7IkmS1BF45XsXt2jRIiKCNWvWNHuZyZMnc9ppp9W/HjduHJdcckmb902SpK6qq39YeoudO+f5dt3e7Mmjyrr+MWPGsGLFiuKTjZvl5ptvpq2eojJ58mTWrFnDQw891Cbra+iPf/wjV1xxBY8//jgbN25k0KBBfO9732PkyJFl2Z4kSW3BgNbFVVVVUVu7s2f77qglYa6S3n33XU444QT+9m//lscff5x+/frx29/+lr59++56YUmSKshTnJ3MuHHjmDZtGpdccgl9+/alf//+3HnnnWzYsIFzzjmHvffem0GDBvH4448DO57inDNnDvvssw91dXUMHTqU6upqJk6cyIoVK+q30fAUZ0OPPvooffr0Yd68eTvt64wZM5g7dy4PP/wwEUFEsGjRIgBeeeUVxo8fz5577sl+++3H+eefz/r163fowzXXXEO/fv2oqalhypQp233qw/XXX8+AAQP43ve+x/HHH8/AgQM56aSTOPzww1v4U5UkqX0Z0DqhuXPnsv/++/OLX/yCadOmccEFF3D66aczZswYXnzxRU466STOOussNm7c2OjyGzdu5Nvf/jb33HMPTz75JG+88QaXXXZZs7Y9f/58zjjjDObNm8ekSZN2WnvZZZfxmc98pj4ArlixgjFjxrBhwwZOPvlk+vbty/PPP8/999/PggULmDp16nbLP/HEEyxZsoRFixZx77338oMf/IBrrrmmfv6PfvQjRo4cyemnn84BBxzAsccey5133tms/ZAkqZIMaJ3Q8OHDufLKKxk8eDDTp0+nV69e7L///px33nkMHjyYq666irfffpuXX3650eW3bt3K7bffzsiRIznuuOOYOnUqTzzxxC63O2vWLC688EIeeeQRTj311F3WV1dXs+eee9KzZ09qa2upra2lqqqK+fPns2nTJu6++26OPPJIxo8fz6233so999zDqlV/+fjVqqoq7rrrLoYNG8Ypp5zCzJkz+e53v1v/0Vz/9V//xW233cbgwYOpq6vjggsu4Atf+AJz585t5k9SktSZnTvn+e2mPPEatE7o6KOPrv++e/fu7Lfffhx11FH1bf37Fz4ha/Xq1dTU1OywfO/evbc7DXjggQeyevXqHepKPfDAA6xevZqnn36aUaN278aGJUuWMHz4cPbaa6/6thNOOIFt27axdOnS+v4PHz58u095GD16NOvXr+fNN9/k0EMPZdu2bYwcOZKvf/3rABx77LG8+uqr3H777Zx99tm71UdJksrJEbROqOET8CNiu7biw1ib+hD4xpbf1V2bxx57LP369eOuu+5qszs8d9eBBx7IRz7yke3ahg4dyhtvvFGhHkmS1DwGNLWJww8/nIULF/Lwww8zbdq0Zi9XVVVV/7FaRUOHDuWll15iw4YN9W1PP/003bp1Y8iQIfVtL730Eu+9917962effZbq6moGDBgAFEbdli5dut26//M//5NDDz20RfsmSVJ7M6CpzRxxxBEsXLiQBx98sNkPrj3ssMN4+eWXWbp0KW+99RZbt25l0qRJ9OrVi7PPPptXX32VhQsXMm3aNM4666z605sAW7Zs4dxzz+W1117jscce4+qrr2bq1Kl061b4Z33ppZfy7LPP8vWvf53f/e53zJ8/nzvuuIOLLrqoHLsvSVKb8Rq0Fir3g2M7uiFDhvDTn/6UcePG0b17d2644Yad1p933nksWrSIkSNHsn79ehYuXMi4ceOoq6vj4osvZtSoUfTu3ZtPf/rT3Hjjjdste+KJJzJ48GDGjh3L5s2bOeOMM5gxY0b9/FGjRvHDH/6Q6dOnM3PmTAYOHMhNN920y7tLJUmqtMjL9UKVEBE1wNq1a9fucLH8pk2bWLZsGQMHDqRXr16V6aCaVK5PIPC4S1LX0fDOzXIPwqxbt674sPc+KaV1O6v1FKckSVLOGNBUVtXV1U1OTz31VKW7J0lSLnkNmspq8eLFTc476KCDWr3eOXPmtHpZSZLyzoCmsho0aFCluyBJUofjKU5JkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDWhe3aNEiIoI1a9Y0e5nJkydz2mmn1b8eN25csz97U5Ik7ZqP2Wip+Z9t3+2d+f2yrn7MmDGsWLGi+NETzXLzzTfTVh8RVq6PbAK47bbbuO222/j9738PwLBhw7jqqqv4+7//+zbfliRJbcmA1sVVVVVRW1vbomVaEuYq6eCDD+Yb3/gGgwcPJqXE3Llz+Yd/+Ad+9atfMWzYsEp3T5KkJnmKs5MZN24c06ZN45JLLqFv377079+fO++8kw0bNnDOOeew9957M2jQIB5//HFgx1Occ+bMYZ999qGuro6hQ4dSXV3NxIkTWbFiRf02Gp7ibOjRRx+lT58+zJs3b6d9nTFjBnPnzuXhhx8mIogIFi1aBMArr7zC+PHj2XPPPdlvv/04//zzWb9+/Q59uOaaa+jXrx81NTVMmTKFLVu21Nd84hOf4OMf/ziDBw/miCOO4Gtf+xrV1dU8++yzLfypSpLUvgxondDcuXPZf//9+cUvfsG0adO44IILOP300xkzZgwvvvgiJ510EmeddRYbN25sdPmNGzfy7W9/m3vuuYcnn3ySN954g8suu6xZ254/fz5nnHEG8+bNY9KkSTutveyyy/jMZz5THwBXrFjBmDFj2LBhAyeffDJ9+/bl+eef5/7772fBggVMnTp1u+WfeOIJlixZwqJFi7j33nv5wQ9+wDXXXNPotj744APuu+8+NmzYwOjRo5u1L5IkVYoBrRMaPnw4V155JYMHD2b69On06tWL/fffn/POO4/Bgwdz1VVX8fbbb/Pyyy83uvzWrVu5/fbbGTlyJMcddxxTp07liSee2OV2Z82axYUXXsgjjzzCqaeeusv66upq9txzT3r27EltbS21tbVUVVUxf/58Nm3axN13382RRx7J+PHjufXWW7nnnntYtWpV/fJVVVXcddddDBs2jFNOOYWZM2fy3e9+l23bttXXvPLKK1RXV9OzZ0+mTJnCD3/4Qz7ykY8046coSVLleA1aJ3T00UfXf9+9e3f2228/jjrqqPq2/v37A7B69Wpqamp2WL53794cfvjh9a8PPPBAVq9evdNtPvDAA6xevZqnn36aUaNG7Vb/lyxZwvDhw9lrr73q20444QS2bdvG0qVL6/s/fPhwevfuXV8zevRo1q9fz5tvvsmhhx4KwJAhQ1i8eDFr167lgQce4Oyzz+Y//uM/DGmSpFxzBK0T2mOPPbZ7HRHbtUUEwHYjTbtafld3bR577LH069ePu+66q83u8GwLVVVVDBo0iBEjRnDdddcxfPhwbr755kp3S5KknTKgqU0cfvjhLFy4kIcffphp06Y1e7mqqio++OCD7dqGDh3KSy+9xIYNG+rbnn76abp168aQIUPq21566SXee++9+tfPPvss1dXVDBgwoMntbdu2jc2bNze7f5IkVYIBTW3miCOOYOHChTz44IPNfnDtYYcdxssvv8zSpUt566232Lp1K5MmTaJXr16cffbZvPrqqyxcuJBp06Zx1lln1Z/eBNiyZQvnnnsur732Go899hhXX301U6dOpVu3wj/r6dOn8+STT/L73/+eV155henTp7No0aJd3rwgSVKleQ1aS5X5wbEd3ZAhQ/jpT3/KuHHj6N69OzfccMNO68877zwWLVrEyJEjWb9+PQsXLmTcuHHU1dVx8cUXM2rUKHr37s2nP/1pbrzxxu2WPfHEExk8eDBjx45l8+bNnHHGGcyYMaN+/urVq/n85z9f/yDeo48+mrq6OiZMmFCOXZckqc1Enq4Xam8RUQOsXbt27Q4Xy2/atIlly5YxcOBAevXqVZkOqknl+gQCj7skdR3nznl+u9ezJ+/eTW67sm7duuLD3vuklNbtrNZTnJIkSTljQFNZVVdXNzk99dRTle6eJEm55DVoKqvFixc3Oe+ggw5q9XrnzJnT6mUlSco7A5rKatCgQZXugiRJHY6nOHehK99E0RV5vCVJeWBAa0L37t2BwrO21HUUj3fx+EuSVAme4mxCjx496N27N3/605/YY4896h9+qs5r27Zt/OlPf6J379706OGvhiSpcvwr1ISI4MADD2TZsmW8/vrrle6O2km3bt045JBD6j+vVJKkSjCg7URVVRWDBw/2NGcXUlVV5WipJKniWhzQImIs8GVgBHAg8KmU0kPZvD2Aa4GPA38FrAUWAP+SUlpeso59gVuATwDbgAeBi1NK60tqjgZmAaOAPwG3pJS+2aAvpwNfBQ4DfgtckVJ6rKX7tDPdunXzifKSJKldtWaoYC/gJeCiRub1Bo6jEJqOA/47MAT4UYO6ecAwYAJwKjAWuKM4M/sIpp8Ar1MIgl8GZkTE+SU1Y4B7gdnAscBDwEMRcWQr9kmSJCk3WjyCllJ6HHgc2OE6nZTSWgqhq15ETAV+ERGHpJTeiIihwERgVErpl1nNNOCxiLgsG2mbBFQB/5RS2gL8OiKOAb7IX4LcxcCPU0rfyl5/JSImAFOBKS3dL0mSpLxoj4tt+gAJWJO9Hg2sKYazzAIKpzo/WlLzZBbOiuqAIRHRt6RmQYNt1WXtjYqInhFRU5yAvVuxP5IkSWVV1oAWEb2A64F7Sz61vRZYXVqXUnofeCebV6xZ1WB1q0rm7aymlqZNp3BdXHH6Q7N2RJIkqR2VLaBlNwz8f0AAF5RrOy10HYURveJ0cGW7I0mStKOyPGajJJwdCowvGT0DWAkc0KC+B7BvNq9Y07/BavuXzNtZzUqakFLaDGwu2e6udkWSJKndtfkIWkk4Gwz8XUrp7QYlzwD7RMSIkrbxWV+eK6kZm62raAKwNKX0bknNiQ3WPSFrlyRJ6rBaHNAiojoijsnuqgQYmL0+JAtUDwAjKdyJ2T0iarOpCiCltAT4MXBnRBwfEScAtwL3lTwrbT6wBZgdEcMi4rMU7tq8saQrNwMTI+JLEfHhiJiRbffWlu6TJElSnrRmBG0k8KtsgkJo+hUwEzgI+CSFa7sWAytKpjEl65gE/AZ4AngM+BlQ/4yz7HEdJwEDgReAG4CZKaU7Smp+DpyZLfcS8I/AaSmlV1uxT5IkSbnRmuegLaJw4X9TdnlhV0rpHQrhamc1LwN/s4ua+4H7d7U9SZKkjsQPHZQkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOtDigRcTYiHgkIpZHRIqI0xrMj4iYGRErIuK9iFgQEYMb1OwbEfMiYl1ErImI2RFR3aDm6Ih4KiI2RcSbEXF5I305PSJ+k9W8EhEfb+n+SJIk5U1rRtD2Al4CLmpi/uXAF4ApwEeBDUBdRPQqqZkHDAMmAKcCY4E7ijMjogb4CfA6MAL4MjAjIs4vqRkD3AvMBo4FHgIeiogjW7FPkiRJudGjpQuklB4HHgeIiO3mRaHhEuDalNLDWdvngVXAacB9ETEUmAiMSin9MquZBjwWEZellJYDk4Aq4J9SSluAX0fEMcAX+UuQuxj4cUrpW9nrr0TEBGAqhXAoSZLUIbX1NWgDgVpgQbEhpbQWeA4YnTWNBtYUw1lmAbCNwohbsebJLJwV1QFDIqJvSc0CtldXsp0dRETPiKgpTsDeLdk5SZKk9tDWAa02+7qqQfuqknm1wOrSmSml94F3GtQ0tg6aUVNL06YDa0umP+ykVpIkqSK62l2c1wF9SqaDK9sdSZKkHbX4GrRdWJl97Q+sKGnvDywuqTmgdKGI6AHsW7L8ymyZUv1L5u2sZiVNSCltBjaXbLepUkmSpIpp6xG0ZRQC0onFhuxar48Cz2RNzwD7RMSIkuXGZ315rqRmbETsUVIzAViaUnq3pOZEtjehZDuSJEkdUmueg1YdEcdkd1UCDMxeH5JSSsBNwJUR8cmIOAq4G1hO4TEYpJSWAD8G7oyI4yPiBOBW4L7sDk6A+cAWYHZEDIuIz1K4a/PGkq7cDEyMiC9FxIcjYgYwMluXJElSh9WaU5wjgYUlr4uhaS4wGfgmhWel3QHsA/wMmJhS2lSyzCQKQeoJCndvPkjh2WlA4c7PiDgJmAW8ALwFzEwp3VFS8/OIOBO4Fvg68FvgtJTSq63YJ0mSpNxozXPQFgFNXryVjaJdlU1N1bwDnLmL7bwM/M0uau4H7t9ZjSRJUkfT1e7ilCRJyj0DmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTlTI9Kd0CSJKkSpq26skFLXUX60RhH0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScafOAFhHdI+KrEbEsIt6LiP8TEV+JiCipiYiYGRErspoFETG4wXr2jYh5EbEuItZExOyIqG5Qc3REPBURmyLizYi4vK33R5Ikqb2VYwTtCuACYCowNHt9OTCtpOZy4AvAFOCjwAagLiJ6ldTMA4YBE4BTgbHAHcWZEVED/AR4HRgBfBmYERHnl2GfJEmS2k2PMqxzDPBwSunR7PXvI+IM4HgojJ4BlwDXppQezto+D6wCTgPui4ihwERgVErpl1nNNOCxiLgspbQcmARUAf+UUtoC/DoijgG+SEmQkyRJ6mjKMYL2c+DEiDgCICKGA38NPJ7NHwjUAguKC6SU1gLPAaOzptHAmmI4yywAtlEYcSvWPJmFs6I6YEhE9G2sYxHRMyJqihOwd+t3U5IkqTzKMYL2DaAG+E1EfAB0B/4tpTQvm1+bfV3VYLlVJfNqgdWlM1NK70fEOw1qljWyjuK8dxvp23Tg6ubviiRJUvsrxwjaZyicfjwTOA44G7gsIs4uw7Za6jqgT8l0cGW7I0mStKNyjKB9C/hGSum+7PUrEXEohdGrucDKrL0/sKJkuf7A4uz7lcABpSuNiB7AviXLr8yWKdW/ZN4OUkqbgc0l62zWDkmSJLWncoyg9aZwrVipD0q2tYxCgDqxODO7HuyjwDNZ0zPAPhExomQd47N1PFdSMzYi9iipmQAsTSk1dnpTkiSpQyhHQHsE+LeIOCUiDouIT1G4s/KHACmlBNwEXBkRn4yIo4C7geXAQ1nNEuDHwJ0RcXxEnADcCtyX3cEJMB/YAsyOiGER8VngYuDGMuyTJElSuynHKc5pwFeB/0nhNOVy4H8BM0tqvgnsReFxGPsAPwMmppQ2ldRMohDKnqAwIvcghWenAYU7PyPiJGAW8ALwFjAzpeQjNiRJUocWhQGtrik7tbp27dq11NTUVLo7kiSpHS2+/uTtXh9zRV1Zt7du3Tr69OkD0CeltG5ntX4WpyRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknLGgCZJkpQzBjRJkqScMaBJkiTljAFNkiQpZwxokiRJOWNAkyRJyhkDmiRJUs4Y0CRJknKmLAEtIg6KiP83It6OiPci4pWIGFkyPyJiZkSsyOYviIjBDdaxb0TMi4h1EbEmImZHRHWDmqMj4qmI2BQRb0bE5eXYH0mSpPbU5gEtIvoCTwNbgb8HPgJ8CXi3pOxy4AvAFOCjwAagLiJ6ldTMA4YBE4BTgbHAHSXbqQF+ArwOjAC+DMyIiPPbep8kSZLaU48yrPMK4M2U0jklbcuK30REAJcA16aUHs7aPg+sAk4D7ouIocBEYFRK6ZdZzTTgsYi4LKW0HJgEVAH/lFLaAvw6Io4BvkhJkJMkSepoynGK85PALyPi/ohYHRG/iojzSuYPBGqBBcWGlNJa4DlgdNY0GlhTDGeZBcA2CiNuxZons3BWVAcMyUbxdhARPSOipjgBe7d+NyVJksqjHAHtr4ALgN8CJwO3Ad+NiLOz+bXZ11UNlltVMq8WWF06M6X0PvBOg5rG1lG6jYamA2tLpj/senckSZLaVzkCWjfgxZTSv6aUfpVSugO4k8L1ZpV2HdCnZDq4st2RJEnaUTkC2grgtQZtS4BDsu9XZl/7N6jpXzJvJXBA6cyI6AHs26CmsXWUbmM7KaXNKaV1xQn48853RZIkqf2VI6A9DQxp0HYEhbstoXDDwErgxOLM7HqwjwLPZE3PAPtExIiSdYzP+vtcSc3YiNijpGYCsDSlVHrHqCRJUodSjoD2HeBjEfGvETEoIs4EzgdmAaSUEnATcGVEfDIijgLuBpYDD2U1S4AfA3dGxPERcQJwK3BfdgcnwHxgCzA7IoZFxGeBi4Eby7BPkiRJ7abNH7ORUno+Ij5F4XqvqyiMmF2SUppXUvZNYC8Kj8PYB/gZMDGltKmkZhKFUPYEhbs3H6Tw7LTidtZGxEkUgt8LwFvAzOyaN0mSpA6rHM9BI6X0v4H/vZP5iUJ4u2onNe8AZ+5iOy8Df9PKbkqSJOWSn8UpSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUM2X5JAH9xblznt+hbfbkURXoiSRJ6igcQZMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTlT9oAWEf8SESkibipp6xURsyLi7YhYHxEPRkT/BssdEhGPRsTGiFgdEd+KiB4NasZFxIsRsTkifhcRk8u9P5IkSeVW1oAWEaOA/wG83GDWd4BPAKcD/w34EPCDkuW6A48CVcAY4GxgMjCzpGZgVrMQOAa4Cfj3iDi5HPsiSZLUXsoW0CKiGpgHnAe8W9LeBzgX+GJK6acppReAc4AxEfGxrOwk4CPA/5NSWpxSehz4CnBRRFRlNVOAZSmlL6WUlqSUbgUeAC4t1z5JkiS1h3KOoM0CHk0pLWjQPgLYA6hvTyn9BngDGJ01jQZeSSmtKlmuDqgBhpXUNFx3Xck6dhARPSOipjgBe7dslyRJksqvx65LWi4iPgccB4xqZHYtsCWltKZB+6psXrFmVSPzaUZNTUTsmVJ6r5FtTweu3uUOSJIkVVCbj6BFxADgZmBSSmlTW69/N10H9CmZDq5sdyRJknZUjlOcI4ADgBcj4v2IeJ/CjQBfyL5fBVRFxD4NlusPrMy+X5m9bjifZtSsa2L0jJTS5pTSuuIE/LlluyZJklR+5QhoTwBHUbizsjj9ksINA8XvtwInFheIiCHAIcAzWdMzwFERcUDJeicA64DXSmpOZHsTStYhSZLUIbX5NWgppT8Dr5a2RcQG4O2U0qvZ69nAjRHxDoXQdQvwTErp2WyRn1AIYvdExOUUrje7FpiVUtqc1dwOTI2IbwJ3AeOBzwCntPU+SZIktaey3CTQDJcC24AHgZ4U7r68sDgzpfRBRJwK3EZhRGwDMBe4qqRmWUScQuGZahcDfwD+OaVU1147IUmSVA7tEtBSSuMavN4EXJRNTS3zOvDxXax3EXDs7vdQkiQpP/wsTkmSpJwxoEmSJOWMAU2SJClnDGiSJEk5Y0CTJEnKGQOaJElSzhjQJEmScsaAJkmSlDMGNEmSpJwxoEmSJOWMAU2SJClnDGiSJEk5Y0CTJEnKGQOaJElSzhjQJEmScsaAJkmSlDMGNEmSpJwxoEmSJOVMj0p3QJIkqdzOnfP8Dm3TKtCP5nIETZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknGnzgBYR0yPi+Yj4c0SsjoiHImJIg5peETErIt6OiPUR8WBE9G9Qc0hEPBoRG7P1fCsiejSoGRcRL0bE5oj4XURMbuv9kSRJam/lGEH7b8As4GPABGAP4CcRsVdJzXeATwCnZ/UfAn5QnBkR3YFHgSpgDHA2MBmYWVIzMKtZCBwD3AT8e0ScXIZ9kiRJajc9dl3SMimliaWvs1Gt1cAI4MmI6AOcC5yZUvppVnMOsCQiPpZSehY4CfgI8HcppVXA4oj4CnB9RMxIKW0BpgDLUkpfyja1JCL+GrgUqGvr/WpL5855foe22ZNHVaAnkiQpj9rjGrQ+2dd3sq8jKIyqLSgWpJR+A7wBjM6aRgOvZOGsqA6oAYaV1Cxge3Ul69hBRPSMiJriBOzd8t2RJEkqr7IGtIjoRuHU49MppVez5lpgS0ppTYPyVdm8Ys2qRubTjJqaiNiziS5NB9aWTH9o1o5IkiS1o3KPoM0CjgQ+V+btNNd1FEb0itPBle2OJEnSjtr8GrSiiLgVOBUYm1IqHalaCVRFxD4NRtH6Z/OKNcc3WGX/knnFr/0bqVmXUnqvsT6llDYDm0v62LydkSRJHUZj13p3NOV4zEZk4exTwPiU0rIGJS8AW4ETS5YZAhwCPJM1PQMcFREHlCw3AVgHvFZScyLbm1CyDkmSpA6pHCNos4AzgX8A/hwRxWvG1qaU3ksprY2I2cCNEfEOhdB1C/BMdgcnwE8oBLF7IuJyCtebXQvMykbBAG4HpkbEN4G7gPHAZ4BTyrBPkiRJ7aYcAe2C7OuiBu3nAHOy7y8FtgEPAj0p3H15YbEwpfRBRJwK3EZhRGwDMBe4qqRmWUScQuGZahdTuOD/n1NKuX7EhiRJan/TVl1Z6S60SDmeg7bLC7tSSpuAi7KpqZrXgY/vYj2LgGNb2EVJkqRc87M4JUmScsaAJkmSlDMGNEmSpJwxoEmSJOWMAU2SJClnDGiSJEk5Y0CTJEnKGQOaJElSzpTtw9IlSZLKrTN8MHpjDGhl1thHS9zS/9oK9ESSJHUUBrScaOx/ALMnj6pATyRJUqV5DZokSVLOGNAkSZJyxoAmSZKUMwY0SZKknPEmAUmS1CF01kdqNMaAJkmSOpXGHnHV0RjQcsxHb0iS1DV5DZokSVLOGNAkSZJyxoAmSZKUMwY0SZKknPEmgQ7GGwckSer8DGiSJCl3utIzzxrjKU5JkqSccQRNkiRVVFcfLWuMAU2SJHVYneFTAxrjKU5JkqSccQStAhpL+7f0v7YCPZEkqX15OrN5DGidgI/ekCTlkWGs9QxonZShTZLU2XTW680a4zVokiRJOeMIWk60x3VpjqpJktqCpy7Lz4CmHRjkJEmqLANaF+f/giRJRXn6m9CVrjdrjAEtx/L0OI7m/NI6yiZJHYdhLN8MaGozzf1lN8hJUuu09hIUw1jHY0DrYPI0qtZau/NGYbiT1FU0970yT+FLbceApg7FGxgkdSRd6T3LkbG2FSmlSvehYiKiBli7du1aampqyrKNxdefXJb1tkZHG2nLk876hip1Zc0NT45Q7aizhrFjrqgr6/rXrVtHnz59APqklNbtrNaA1oUCWmMMbfnQ3ADYHn8o8hJGd2fkoSuNWrSH9jgWhqD211lD1u4woOWEAW33GO6UB839Y98eoaASfTHsdC2GqvIyoLWhiLgI+DJQC7wETEsp/aKZyxrQKqCxYLc7bzoGRUl50Nz3sbZ+D1TbMaC1kYj4LHA3MAV4DrgEOB0YklJa3YzlDWhqtXK/ybZ18NydPx550dy7mDvD3c6Naev9ao+fp8FDHYkBrY1ExHPA8ymlqdnrbsCbwC0ppW80Y3kDmiRJAvIV0DrsYzYiogoYAVxXbEspbYuIBcDoJpbpCfQsadobCj+wclm/6f2yrVuSJLWdcuaBlq6/wwY0YH+gO7CqQfsq4MNNLDMduLph44ABA9q2Z5IkqeOZ0ae9trQ30DlH0FrpOuDGBm37Au+UaXt7A38ADgb+XKZtqHk8FvnhscgHj0N+eCzyob2Ow97A8l0VdeSA9hbwAdC/QXt/YGVjC6SUNgObGzSXbTwzIorf/nlX55pVXh6L/PBY5IPHIT88FvnQjsehWevuVsYOlFVKaQvwAnBisS27SeBE4JlK9UuSJGl3deQRNCicrpwbEb8EfkHhMRt7Ad+rZKckSZJ2R4cOaCml70dEP2AmhQfVLgYmppQa3jhQKZuBa9jxtKran8ciPzwW+eBxyA+PRT7k6jh06OegSZIkdUYd9ho0SZKkzsqAJkmSlDMGNEmSpJwxoEmSJOWMAW03RcRFEfH7iNgUEc9FxPG7qD89In6T1b8SER9vr752di05FhFxXkQ8FRHvZtOCXR07NU9LfydKlvtcRKSIeKjMXewyWvH+tE9EzIqIFRGxOSL+0/eottGKY3FJRCyNiPci4s2I+E5E9Gqv/nZGETE2Ih6JiOXZe81pzVhmXES8mP0+/C4iJpe/pwUGtN0QEZ+l8Cy2a4DjgJeAuog4oIn6McC9wGzgWOAh4KGIOLJdOtyJtfRYAOMoHIu/BUYDbwI/iYiDyt/bzqsVx6G43GHAt4Gnyt3HrqIV709VwP8PHAb8IzAEOA/4Y3v0tzNrxbE4E/hGVj8UOBf4LPD1dulw57UXhZ/9Rc0pjoiBwKPAQuAY4Cbg3yPi5DL1b/vt+5iN1ouI54DnU0pTs9fdKPyhvyWl9I1G6r8P7JVSOrWk7VlgcUppSjt1u1Nq6bFoZPnuwLvA1JTS3WXtbCfWmuOQ/eyfBO4C/gbYJ6V0Wvv0uPNqxfvTFODLwIdTSlvbtbOdXCuOxa3A0JRS6Sfl3AB8NKX01+3U7U4tIhLwqZTSQzupuR44JaV0ZEnbfRTeoyaWu4+OoLVS9r/NEcCCYltKaVv2enQTi40urc/U7aRezdDKY9FQb2AP4J0272AXsRvH4SpgdUppdnl72HW08lh8ksLH5M2KiFUR8WpE/GsWoNVKrTwWPwdGFE+DRsRfAR8HHitvb9VARf9md+hPEqiw/YHuQMNPLVgFfLiJZWqbqK9t2651Oa05Fg1dDyxnx19GNV+Lj0NE/DWF0zfHlLVnXU9rfif+ChgPzKMQBgYB/5PCf1yuKU83u4QWH4uU0vyI2B/4WRQ+wbsHcHtKyVOc7aupv9k1EbFnSum9cm7cETR1eRHxL8DnKAx3b6p0f7qKiNgbuAc4L6X0VqX7I7oBq4HzU0ovpJS+D3wN8PKLdhYR44B/BS6kcM3afwdOiYivVLBbameOoLXeW8AHQP8G7f2BlU0ss7KF9Wqe1hwLACLiMuBfgL9LKb1cnu51GS09DodTuCD9kcIgAZD9pzEi3geGpJT+T1l62vm15ndiBbA1pfRBSdsSoDYiqlJKW9q+m11Ca47FV4F7Ukr/nr1+JSL2Au6IiK9lp0hVfk39zV5X7tEzcASt1bI3qxeA0os4u2Wvn2lisWdK6zMTdlKvZmjlsSAiLge+AkxMKf2y3P3s7FpxHH4DHEXh9GZx+hF/uWPqzTJ2t1Nr5e/E08CgrK7oCGCF4az1WnksegMNQ1gxOAdqL5X9m51ScmrlROG2503A2RRuhf5fFO4E7J/Nvxu4rqR+DLAV+BKFaw9mAFuAIyu9Lx19asWxuALYDHyawnUGxam60vvSkaeWHodGlp8DPFTp/egMUyt+JwYA64BbKASzUyhcb/Nvld6Xjj614ljMyI7F54CBFELB74DvV3pfOvIEVPOX/wwm4NLs+0Oy+dcBd5fUDwQ2AN/M/mZfCLwPnNwe/fUU525IKX0/IvoBMyn8cV9MYTSmeFHhIZT8Lyil9PPs+TbXUniezW+B01JKr7Zrxzuhlh4L4AKgCnigwaquofDmqFZoxXFQmbTi/enN7PlO3wFepvD8s5sp3ECj3dCK34trKQSIa4GDgD8BjwD/1l597qRGUhihL7ox+zoXmAwcSOFYAJBSWhYRp1D4nbgY+APwzymluvborM9BkyRJyhmvQZMkScoZA5okSVLOGNAkSZJyxoAmSZKUMwY0SZKknDGgSZIk5YwBTZIkKWcMaJIkSTljQJMkScoZA5okSVLOGNAkSZJyxoAmSZKUM/8XaSzGhnOU97gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.hist(minik_top6, bins=100, label='minik_top6', alpha = 0.7)\n",
    "plt.hist(minik_top3, bins=100, label='minik_top3', alpha = 0.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.hist(anet_top6, bins=100, label='anet_top6', alpha = 0.8)\n",
    "plt.hist(anet_top3, bins=100, label='anet_top3', alpha = 0.8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.asarray(results)\n",
    "b = np.asarray(sampled_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(a, './tensors/minik_u10to1_logit_s_result.pt')\n",
    "torch.save(b, './tensors/minik_u10to1_logit_s_indice.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idataloader = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(idataloader)\n",
    "# imgs, labels = data['imgs'], data['label'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "perm_num = 6\n",
    "with torch.no_grad():\n",
    "    imgs, labels = data['imgs'], data['label'].squeeze()\n",
    "    imgs, labels = imgs.cuda(), labels.cuda()\n",
    "    B, N, C, T, H, W = imgs.shape\n",
    "    imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "    # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "    x = model.extract_feat(imgs.unsqueeze(2))\n",
    "    logits = model.cls_head(x) # B*T num_classes\n",
    "    logits = logits.softmax(-1)\n",
    "    logits = logits.reshape(B, T, -1)\n",
    "    label_logits = logits[range(B), :, labels.squeeze()]\n",
    "\n",
    "    max_idx = label_logits.topk(1, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "    batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "    imgs = rearrange(imgs, '(b t) c h w -> b t c h w', b=B, t=T)\n",
    "    sampled_imgs = imgs[batch_inds, max_idx]\n",
    "    sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "    fx = model.extract_feat(sampled_imgs)\n",
    "    flogits = model.cls_head(fx)\n",
    "    result = flogits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = data['imgs'].cuda(), data['label'].cuda()\n",
    "with torch.no_grad():\n",
    "    B, N, C, T, H, W = imgs.shape\n",
    "    imgs = rearrange(imgs, 'b n c t h w -> (b n t) c h w')\n",
    "    # imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "    x = model.extract_feat(imgs.unsqueeze(2))\n",
    "    logits = model.cls_head(x) # B*T num_classes\n",
    "    # logits = logits.softmax(-1)\n",
    "    negative_entropy = (logits * torch.log(logits)).sum(-1)\n",
    "    negative_entropy = negative_entropy.reshape(B, T)\n",
    "    max_idx = negative_entropy.topk(6, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "    batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "    imgs = rearrange(imgs, '(b t) c h w -> b t c h w', b=B, t=T)\n",
    "    sampled_imgs = imgs[batch_inds, max_idx]\n",
    "    sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "\n",
    "    fx = model.extract_feat(sampled_imgs)\n",
    "    flogits = model.cls_head(fx)\n",
    "    result = flogits.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.1330e-01, 1.8330e-01, 3.2580e-03, 1.4101e-04])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor( [7.64,  6.15,  2.12, -1.02]).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.298317366548036"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4935, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(logits[0] * torch.log(logits[0])).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4538, -2.5542, -2.0615, -1.9998, -2.0039, -4.1134, -4.1134, -4.1134,\n",
       "        -4.1134, -4.1134], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_entropy[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0801, 0.1262, 0.0321, 0.0498, 0.0791, 0.0282, 0.0282, 0.0282, 0.0282,\n",
       "        0.0282], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_logits[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = data['imgs'], data['label'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.reshape(50, 3, 10, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10, 3, 224, 224])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 224, 224])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 224, 224])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_imgs = perm_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_285329/738139643.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0munorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m123.675\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m116.28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m103.53\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m58.395\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m57.12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m57.375\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mu_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mu_sampled_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_sampled_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_285329/738139643.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \"\"\"\n\u001b[1;32m     21\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "idx = torch.randint(0,50,[1,])\n",
    "\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        tensor=tensor.clone()\n",
    "        f, c, h, w = tensor.shape\n",
    "        for img in tensor:\n",
    "            for t, m, s in zip(img, self.mean, self.std):\n",
    "                t.mul_(s).add_(m)\n",
    "                # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "    def show(imgs):\n",
    "        if not isinstance(imgs, list):\n",
    "            imgs = [imgs]\n",
    "        fix, axs = plt.subplots(nrows=len(imgs), squeeze=False, figsize=(40,14))\n",
    "        # plt.suptitle(f'Label - {label_map[label]}, Path - {path}',fontsize=20)\n",
    "        fix.tight_layout()\n",
    "        for i, img in enumerate(imgs):\n",
    "            img = img.detach()\n",
    "            img = to_pil_image(img)\n",
    "            axs[i, 0].imshow(np.asarray(img))\n",
    "            axs[i, 0].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "unorm = UnNormalize(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375])\n",
    "u_imgs = unorm(imgs[idx][0])\n",
    "u_sampled_imgs = unorm(sampled_imgs[idx].transpose(1,2)[0])\n",
    "grid = [make_grid(u_imgs.to(torch.uint8), 10), make_grid(u_sampled_imgs.to(torch.uint8), 2)]\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5257, -0.3109,  0.1788, -0.7290, -1.1499, -1.2177,  0.2845, -0.2046,\n",
       "         3.6867,  0.4259], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10, 3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0][[0,2,6,7,8,9]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 6, 7, 8, 9], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=imgs[0][[0,2,6,7,8,9]]\n",
    "b=sampled_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.reshape(B * T, C, H, W) # B*T C H W\n",
    "x = model.extract_feat(imgs.unsqueeze(2))\n",
    "logits = model.cls_head(x) # B*T num_classes\n",
    "logits = logits.reshape(B, T, -1)\n",
    "label_logits = logits[range(B), :, labels.squeeze()]\n",
    "\n",
    "# max_idx = label_logits.topk(1, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "# batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "# result = logits[batch_inds, max_idx].squeeze()\n",
    "\n",
    "max_idx = label_logits.max(-1)[1]\n",
    "result = logits[range(B), max_idx, :]\n",
    "\n",
    "result = result.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idataloader = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(idataloader)\n",
    "# imgs, labels = data['imgs'], data['label'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_seg = 10\n",
    "perm_num = 2\n",
    "perms = list(combinations([i for i in range(total_seg)],perm_num))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imgs, labels = data['imgs'], data['label'].squeeze()\n",
    "    imgs, labels = imgs.cuda(), labels.cuda()\n",
    "    B, N, C, T, H, W = imgs.shape\n",
    "    perm_imgs = []\n",
    "    score = torch.zeros([B, total_seg]).cuda()\n",
    "    for perm in perms:\n",
    "        indice = torch.tensor([1 if i in perm else 0 for i in range(total_seg)]).bool()\n",
    "        perm_imgs.append(imgs[:,:,:,indice])\n",
    "    perm_imgs = torch.stack(perm_imgs, 1)\n",
    "    perm_imgs = rearrange(perm_imgs, 'b p n c t h w -> (b p n) c t h w')\n",
    "    x = model.extract_feat(perm_imgs)\n",
    "    logits = model.cls_head(x) # B*len(perms) num_classes\n",
    "    logits = rearrange(logits, '(b p) n -> b p n', b = B, p = len(perms)) # B len(perms) num_classes\n",
    "    label_logits = logits[range(B), :, labels.squeeze()]\n",
    "    total_score = label_logits.mean(-1)\n",
    "    for i in range(total_seg):\n",
    "        tmp = torch.zeros_like(total_score)\n",
    "        for j in range(len(perms)):\n",
    "            if i in perms[j]:\n",
    "                tmp += label_logits[:, j]\n",
    "        score[:, i] = total_score - tmp/9\n",
    "    max_idx = score.topk(6, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "    batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "    imgs = rearrange(imgs, 'b n c t h w -> (b n) t c h w')\n",
    "    sampled_imgs = imgs[batch_inds, max_idx]\n",
    "    sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "    fx = model.extract_feat(sampled_imgs)\n",
    "    flogits = model.cls_head(fx)\n",
    "    result = flogits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8736,  7.4793,  8.0049, 15.2361,  6.2707, 11.8610,  9.4330,  4.9589,\n",
       "         8.0566,  8.2250,  6.4955,  9.3159,  7.6948,  6.3771,  9.8631,  7.9948,\n",
       "         4.9741,  9.3425,  2.7163,  8.2024,  9.5474,  6.4704,  5.7176,  8.1301,\n",
       "         9.9383, 10.6796,  7.1633, 13.5326,  8.5640,  5.2459], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_logits[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1558, -0.1787, -0.0931, -0.0742, -2.2390,  0.8747, -0.6735, -0.3846,\n",
       "         0.7825,  1.8301], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(501.4761, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8736, 11.0055,  9.7906, 13.9045, 10.5663, 12.1575, 12.1909,  9.7229,\n",
       "         8.6814, 11.1525, 12.1052, 12.8016, 10.3786, 12.4423, 11.3939, 10.1923,\n",
       "        10.5636, 11.0809, 14.0698, 10.6421, 12.2827, 11.3482, 10.3151,  9.2359,\n",
       "        14.1013, 10.9181, 12.0799, 11.4991, 10.1141,  9.2743, 12.1695, 14.9192,\n",
       "        14.7238, 12.9157, 10.8409,  9.5833, 10.3983,  9.5909,  8.1758, 12.2316,\n",
       "        11.2830,  9.3769, 10.7069,  9.2638,  8.4117], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.525547  ,  4.232628  ,  4.33488   , ..., -1.4578041 ,\n",
       "         1.1844931 ,  0.83911103],\n",
       "       [10.21198   ,  3.0332232 ,  3.4635575 , ..., -2.4009047 ,\n",
       "         4.6497517 ,  3.302033  ],\n",
       "       [ 9.506054  ,  0.9489721 ,  3.6970081 , ..., -2.774393  ,\n",
       "         3.4367907 , -2.002809  ],\n",
       "       ...,\n",
       "       [15.286939  ,  2.4639966 ,  3.686197  , ..., -1.7040263 ,\n",
       "         1.0236428 ,  1.0594429 ],\n",
       "       [ 9.659581  ,  3.1600344 ,  2.4629824 , ..., -2.1093814 ,\n",
       "         1.8079818 , -1.3402663 ],\n",
       "       [ 7.805283  ,  0.58568823,  4.3149834 , ..., -2.693321  ,\n",
       "         4.7270737 , -2.8046846 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_seg = 10\n",
    "perm_num = 2\n",
    "perms = list(combinations([i for i in range(total_seg)],perm_num))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imgs, labels = data['imgs'], data['label'].squeeze()\n",
    "    imgs, labels = imgs.cuda(), labels.cuda()\n",
    "    B, N, C, T, H, W = imgs.shape\n",
    "    perm_imgs = []\n",
    "    score = torch.zeros([B, total_seg]).cuda()\n",
    "    for perm in perms:\n",
    "        indice = torch.tensor([1 if i in perm else 0 for i in range(total_seg)]).bool()\n",
    "        perm_imgs.append(imgs[:,:,:,indice])\n",
    "    perm_imgs = torch.stack(perm_imgs, 0)\n",
    "    perm_imgs = rearrange(perm_imgs, 'p b n c t h w -> (p b n) c t h w')\n",
    "    x = model.extract_feat(perm_imgs)\n",
    "    logits = model.cls_head(x) # B*len(perms) num_classes\n",
    "    logits = rearrange(logits, '(b p) n -> b p n', b = B, p = len(perms)) # B len(perms) num_classes\n",
    "    label_logits = logits[range(B), :, labels.squeeze()]\n",
    "    for i in range(len(perms)):\n",
    "        for j in range(len(perms[i])):\n",
    "            score[:, perms[i][j]] += label_logits[:, i]\n",
    "    max_idx = score.topk(6, dim=1)[1].sort(dim=1,descending=False)[0]\n",
    "    batch_inds = torch.arange(B).unsqueeze(-1).expand_as(max_idx)\n",
    "    imgs = rearrange(imgs, 'b n c t h w -> (b n) t c h w')\n",
    "    sampled_imgs = imgs[batch_inds, max_idx]\n",
    "    sampled_imgs = rearrange(sampled_imgs, 'b t c h w -> b c t h w')\n",
    "    fx = model.extract_feat(sampled_imgs)\n",
    "    flogits = model.cls_head(fx)\n",
    "    result = flogits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.544764  ,  3.6215591 ,  2.983023  , ..., -1.4017637 ,\n",
       "         1.1687435 ,  0.04351258],\n",
       "       [ 8.651378  ,  3.79117   ,  2.1004863 , ..., -1.9918274 ,\n",
       "         4.472507  ,  1.4226387 ],\n",
       "       [ 9.058618  ,  1.2275242 ,  4.017436  , ..., -3.0507202 ,\n",
       "         3.2552104 , -1.4165667 ],\n",
       "       ...,\n",
       "       [ 9.602396  ,  1.543493  ,  2.7375624 , ...,  1.0918307 ,\n",
       "         3.256653  , -4.211716  ],\n",
       "       [-0.31665733,  0.25631097,  0.19727069, ..., -1.2034167 ,\n",
       "         4.004699  ,  1.7919914 ],\n",
       "       [ 7.5830936 , -0.1668594 ,  4.1315694 , ..., -2.8547604 ,\n",
       "        -0.32634628, -3.6885107 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocsampler",
   "language": "python",
   "name": "ocsampler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "445f7cc94d7363448a34b99cd36c881b588cc1766009096df3118326895cf331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
